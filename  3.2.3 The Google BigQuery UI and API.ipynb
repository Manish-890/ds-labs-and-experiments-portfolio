{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QaGbHIhQLFYq"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMx6dqz7LFYv"
   },
   "source": [
    "\n",
    "# *The Google BigQuery UI and API*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKGiPVSwLFYx"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKMV45iQLFY2"
   },
   "source": [
    "The Google BigQuery UI provides access to Google's extensive collection of public data sets via an SQL-based query engine. \n",
    "\n",
    "The BigQuery API provides programmatic access to the data sets.\n",
    "\n",
    "We can use the UI to discover interesting data before writing Python code to access it. Then we can reproduce it in an API request so as to aggregate large amounts of data on Google's infrastructure before pulling the results into our application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3JonnfULFY6"
   },
   "source": [
    "## BigQuery Web UI\n",
    "\n",
    "Work through the Quickstart at https://cloud.google.com/bigquery/docs/quickstarts/quickstart-web-ui.\n",
    "\n",
    "You will need to set up a Google Cloud Platform account if you don't already have one. (This should not cost anything during the trial period unless you perform a large amount of querying. Afterwards, costs are based on actual resource usage, but most offerings have a free tier.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QM5QOIBpLFY9"
   },
   "source": [
    "## BigQuery API\n",
    "\n",
    "You should already have the Google Cloud Client Library for Python installed (https://cloud.google.com/python/setup).\n",
    "\n",
    "- Open Google Cloud Console (https://console.cloud.google.com/home/) and select to create a project.\n",
    "\n",
    "- Under \"Getting Started\", select \"Enable APIs and get credentials such as keys\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ni9g5D7LFY_"
   },
   "source": [
    "- In the API table, make sure the BigQuery API is enabled. Page back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYjui9nrLFZC"
   },
   "source": [
    "### Authentication\n",
    "\n",
    "Go to https://cloud.google.com/iam/docs/creating-managing-service-account-keys and follow the instructions under \"Create a service account key\" to create a service account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYryTo8SLFZE"
   },
   "source": [
    "- Fill out the form, giving the account an appropriate name, and choose \"Project Owner\" for Account Type.\n",
    "\n",
    "- Click \"Create\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUx6uvpALFZF"
   },
   "source": [
    "- The keys will get saved to your computer.\n",
    "\n",
    "- Note the location and copy the file path (of the json file) to somewhere safe, for future reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnYr6eJ-LFZH"
   },
   "source": [
    "- See here for more information:\n",
    "\n",
    "https://cloud.google.com/iam/docs/understanding-service-accounts?&_ga=2.173177830.-495703703.1532572448#managing_service_account_keys "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQKOrjk8LFZI"
   },
   "source": [
    "This is supposed to get implicit key retrieval working:\n",
    "\n",
    "- Windows:\n",
    "    `set GOOGLE_APPLICATION_CREDENTIALS=[PATH]`\n",
    "    \n",
    "- Linux, MacOS:\n",
    "    `export GOOGLE_APPLICATION_CREDENTIALS=[PATH]`\n",
    "    \n",
    "where `[PATH]` is the full file path of your json key file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pvHgwVcLFZJ"
   },
   "source": [
    "### Using the Python API\n",
    "\n",
    "Google provides Python libraries for wrapping the Google APIs. \n",
    "\n",
    "__(Installing the \"google-cloud-storage\" and \"google-cloud-bigquery\" libraries should cover all the dependencies for this lab.)__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-CFdsY-N6zeO"
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Exi8RHoh65Ic"
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0o5eABcXLFZL"
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery import Dataset\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHZQSxxqLFZR"
   },
   "source": [
    "Invoke a method of the `.Client` object that takes the path to your key files as a string argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8nTBh0TvLFZR"
   },
   "outputs": [],
   "source": [
    "key_path = '[DesktopIODlabsmodules_3]'  # put the path to your json key file here \n",
    "#,                    (or write code to load it from a file that your notebook can easily find)\n",
    "key_path = 'spry-acolyte-384422-743796b53856.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XKIHVy8LFZT"
   },
   "source": [
    "This should not throw an error if key retrieval / assignment worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gfqDJPU9LFZT"
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client.from_service_account_json(key_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1sntjgJLFZU"
   },
   "source": [
    "*Nb. The `storage` object was used in the above example, but there are other objects of interest that have polymorphic `Client` members that are used similarly, such as `bigquery`, which is used below.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSA3wp7NLFZX"
   },
   "source": [
    "Next, execute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ljcqTlxXLFZX"
   },
   "outputs": [],
   "source": [
    "client = bigquery.Client.from_service_account_json(key_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kS1b8GXYLFZY"
   },
   "source": [
    "This client is associated with the default project (which was set or defaulted in the BigQuery UI): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LflN4IlzLFZY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spry-acolyte-384422'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXQNVF1XLFZb"
   },
   "source": [
    "A BigQuery project contains datasets. Datasets contain tables. To get at the data in a table we need to create a reference that covers this hierarchy; in the `bigquery` library this looks like `project.dataset.table`.  \n",
    "\n",
    "(Nb. Queries can be performed on projects and datasets, but most queries are performed on tables.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOtLSyBdLFZb"
   },
   "source": [
    "To explore the public datasets we will start by reassigning our `client` variable using optional `project` parameter (set to `bigquery-public-data`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SQTQ24whLFZc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigquery-public-data\n"
     ]
    }
   ],
   "source": [
    "#project = 'bigquery-public-data'\n",
    "client = bigquery.Client.from_service_account_json(key_path, project = 'bigquery-public-data')\n",
    "print(client.project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZonWy10xLFZe"
   },
   "source": [
    "Here is how to get a list of the datasets in the current project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yQan0v1vLFZe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5944EBD10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A59649BA50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A59649BED0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A59649BF90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A59649B890>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A59464A150>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A593516710>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A594555FD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A594556150>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A59649BE90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964A7910>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964A78D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964A7A90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964A7310>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964A7390>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964A71D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B83D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9410>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B8350>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B93D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BA0D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B8410>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9850>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9A50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9810>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9950>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9750>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9710>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9910>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B97D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B98D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B8290>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9AD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BA050>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B8310>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9550>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B94D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9610>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9650>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9690>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD010>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD050>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD090>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD0D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD110>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD150>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD190>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD1D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD210>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD250>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5944B5550>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A593590110>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A59400DF10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A595180D90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5950EE7D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9C10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9D10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BA010>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9DD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9ED0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9F90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9F50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9E10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9E90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9F10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9E50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD290>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD2D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD310>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD410>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD350>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD390>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD890>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD750>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD7D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD790>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BDD90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BDE90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BDE50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BDE10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BDD10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BDDD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE190>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE150>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BEAD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BDB10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE310>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE590>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BEA50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE210>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE610>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE390>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE3D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE1D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE050>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CD510>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CD550>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CD590>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CD5D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CD610>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5944B5E90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9FD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9C50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD4D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BD450>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE850>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE910>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE8D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE5D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE550>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE790>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE690>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE710>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE6D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE510>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE650>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE410>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE4D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE810>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CD650>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CD690>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CD6D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CD7D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CD710>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CD750>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CDC10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CDBD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CDAD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CDB50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CDB10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE090>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE150>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE110>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE010>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CDF90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CDD50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE950>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CD9D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE8D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE450>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE410>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE310>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CDE10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE390>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE3D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE290>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DD710>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DD750>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DD790>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DD7D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964A5C90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9C90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964B9CD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CD790>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CD890>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CD810>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE5D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE750>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE6D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE710>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CDB90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE4D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE490>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE2D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CDE50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CDFD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE990>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE9D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BDC50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DD810>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DD850>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DD890>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DD990>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DD8D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DD910>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DDD50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DDB10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DDC90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DDD10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DDCD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE190>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE250>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE210>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE110>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DDF90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DDE10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DEA90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DDB90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE350>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DEA10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE9D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE4D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE550>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE410>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DDF50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE490>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE510>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1410>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1450>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1490>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BEA10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DDA10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DDA50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DD9D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE810>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE850>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE750>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE790>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE7D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE590>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE3D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DE0D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964DDE90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE650>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CDA90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE890>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE7D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE610>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964CE810>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E14D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1510>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1550>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1650>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1590>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E15D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1A10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E17D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1950>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E19D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1990>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1E50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1F10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1ED0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1DD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1C50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1AD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E2750>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1850>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E2010>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E26D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E2690>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E2190>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E2210>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E20D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1C10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E2150>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E21D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964C5090>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964C50D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964C5110>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BDBD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964BE950>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E16D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1710>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E1690>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E24D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E2510>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x000002A5964E2410>]\n"
     ]
    }
   ],
   "source": [
    "datasets = list(client.list_datasets())\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UoYS4suLFZg"
   },
   "source": [
    "That wasn't helpful. We need to go deeper into the object structure to get at something meaningful. Actually, the `dataset_id` member contains the name attribute of a `dataset` object; write some code to print that name for each member of the list that was created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MBV3-c21LFZi"
   },
   "outputs": [],
   "source": [
    "#?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VKuobUSLFZk"
   },
   "source": [
    "The google API objects in the `bigquery` library have their own overloads of the format() function that make them easier to read. Below is a function that exploits the `format` method of `project` and `dataset_id`, providing an easy way to list datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "obqd0X0vLFZl"
   },
   "outputs": [],
   "source": [
    "# function for listing datasets in a project:\n",
    "def printDatasetList(client):\n",
    "    project = client.project    #: only one project can be associated with a client instance\n",
    "    datasets = list(client.list_datasets())\n",
    "    if datasets:\n",
    "        print('Datasets in project {}:'.format(project))\n",
    "        for dataset in datasets:  \n",
    "            print('\\t{}'.format(dataset.dataset_id))\n",
    "        found = True\n",
    "    else:\n",
    "        print('{} project does not contain any datasets.'.format(project))\n",
    "        found = False\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TcS8DXenLFZn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in project bigquery-public-data:\n",
      "\tamerica_health_rankings\n",
      "\taustin_311\n",
      "\taustin_bikeshare\n",
      "\taustin_crime\n",
      "\taustin_incidents\n",
      "\taustin_waste\n",
      "\tbaseball\n",
      "\tbitcoin_blockchain\n",
      "\tblackhole_database\n",
      "\tbls\n",
      "\tbls_qcew\n",
      "\tbreathe\n",
      "\tbroadstreet_adi\n",
      "\tcatalonian_mobile_coverage\n",
      "\tcatalonian_mobile_coverage_eu\n",
      "\tcensus_bureau_acs\n",
      "\tcensus_bureau_construction\n",
      "\tcensus_bureau_international\n",
      "\tcensus_bureau_usa\n",
      "\tcensus_opportunity_atlas\n",
      "\tcensus_utility\n",
      "\tcfpb_complaints\n",
      "\tchicago_crime\n",
      "\tchicago_taxi_trips\n",
      "\tclemson_dice\n",
      "\tcloud_storage_geo_index\n",
      "\tcms_codes\n",
      "\tcms_medicare\n",
      "\tcms_synthetic_patient_data_omop\n",
      "\tcountry_codes\n",
      "\tcovid19_aha\n",
      "\tcovid19_covidtracking\n",
      "\tcovid19_ecdc\n",
      "\tcovid19_ecdc_eu\n",
      "\tcovid19_genome_sequence\n",
      "\tcovid19_geotab_mobility_impact\n",
      "\tcovid19_geotab_mobility_impact_eu\n",
      "\tcovid19_google_mobility\n",
      "\tcovid19_google_mobility_eu\n",
      "\tcovid19_govt_response\n",
      "\tcovid19_italy\n",
      "\tcovid19_italy_eu\n",
      "\tcovid19_jhu_csse\n",
      "\tcovid19_jhu_csse_eu\n",
      "\tcovid19_nyt\n",
      "\tcovid19_open_data\n",
      "\tcovid19_open_data_eu\n",
      "\tcovid19_public_forecasts\n",
      "\tcovid19_public_forecasts_asia_ne1\n",
      "\tcovid19_rxrx19\n",
      "\tcovid19_symptom_search\n",
      "\tcovid19_tracking\n",
      "\tcovid19_usafacts\n",
      "\tcovid19_vaccination_access\n",
      "\tcovid19_vaccination_search_insights\n",
      "\tcovid19_weathersource_com\n",
      "\tcrypto_band\n",
      "\tcrypto_bitcoin\n",
      "\tcrypto_bitcoin_cash\n",
      "\tcrypto_dash\n",
      "\tcrypto_dogecoin\n",
      "\tcrypto_ethereum\n",
      "\tcrypto_ethereum_classic\n",
      "\tcrypto_iotex\n",
      "\tcrypto_litecoin\n",
      "\tcrypto_polygon\n",
      "\tcrypto_tezos\n",
      "\tcrypto_theta\n",
      "\tcrypto_zcash\n",
      "\tcrypto_zilliqa\n",
      "\tcymbal_investments\n",
      "\tdataflix_covid\n",
      "\tdataflix_traffic_safety\n",
      "\tdeepmind_alphafold\n",
      "\tdeps_dev_v1\n",
      "\tdimensions_ai_covid19\n",
      "\tebi_chembl\n",
      "\tebi_surechembl\n",
      "\teclipse_megamovie\n",
      "\tepa_historical_air_quality\n",
      "\tethereum_blockchain\n",
      "\tetsi_technical_standards\n",
      "\tfaa\n",
      "\tfcc_political_ads\n",
      "\tfda_drug\n",
      "\tfda_food\n",
      "\tfdic_banks\n",
      "\tfec\n",
      "\tfhir_synthea\n",
      "\tga4_obfuscated_sample_ecommerce\n",
      "\tgbif\n",
      "\tgdelt_hathitrustbooks\n",
      "\tgdelt_internetarchivebooks\n",
      "\tgenomics_cannabis\n",
      "\tgenomics_rice\n",
      "\tgeo_census_blockgroups\n",
      "\tgeo_census_tracts\n",
      "\tgeo_international_ports\n",
      "\tgeo_openstreetmap\n",
      "\tgeo_us_boundaries\n",
      "\tgeo_us_census_places\n",
      "\tgeo_us_roads\n",
      "\tgeo_whos_on_first\n",
      "\tghcn_d\n",
      "\tghcn_m\n",
      "\tgithub_repos\n",
      "\tgnomAD\n",
      "\tgnomAD_asiane1\n",
      "\tgnomAD_eu\n",
      "\tgoogle_ads\n",
      "\tgoogle_analytics_sample\n",
      "\tgoogle_books_ngrams_2020\n",
      "\tgoogle_cfe\n",
      "\tgoogle_cloud_release_notes\n",
      "\tgoogle_dei\n",
      "\tgoogle_patents_research\n",
      "\tgoogle_political_ads\n",
      "\tgoogle_trends\n",
      "\tgrid_ac\n",
      "\thacker_news\n",
      "\thud_zipcode_crosswalk\n",
      "\thuman_genome_variants\n",
      "\thuman_variant_annotation\n",
      "\tidc_current\n",
      "\tidc_current_clinical\n",
      "\tidc_v1\n",
      "\tidc_v10\n",
      "\tidc_v11\n",
      "\tidc_v11_clinical\n",
      "\tidc_v12\n",
      "\tidc_v12_clinical\n",
      "\tidc_v13\n",
      "\tidc_v13_clinical\n",
      "\tidc_v2\n",
      "\tidc_v3\n",
      "\tidc_v4\n",
      "\tidc_v5\n",
      "\tidc_v6\n",
      "\tidc_v7\n",
      "\tidc_v8\n",
      "\tidc_v9\n",
      "\timdb\n",
      "\timmune_epitope_db\n",
      "\tiowa_liquor_sales\n",
      "\tiowa_liquor_sales_forecasting\n",
      "\tirs_990\n",
      "\tlabeled_patents\n",
      "\tlibraries_io\n",
      "\tlistenbrainz\n",
      "\tlondon_bicycles\n",
      "\tlondon_crime\n",
      "\tlondon_fire_brigade\n",
      "\tmarec\n",
      "\tmedicare\n",
      "\tml_datasets\n",
      "\tml_datasets_uscentral1\n",
      "\tmodis_terra_net_primary_production\n",
      "\tmoon_phases\n",
      "\tmultilingual_spoken_words_corpus\n",
      "\tnasa_wildfire\n",
      "\tncaa_basketball\n",
      "\tnces_ipeds\n",
      "\tnew_york\n",
      "\tnew_york_311\n",
      "\tnew_york_citibike\n",
      "\tnew_york_mv_collisions\n",
      "\tnew_york_subway\n",
      "\tnew_york_taxi_trips\n",
      "\tnew_york_trees\n",
      "\tnhtsa_traffic_fatalities\n",
      "\tnih_gudid\n",
      "\tnih_sequence_read\n",
      "\tnlm_rxnorm\n",
      "\tnoaa_global_forecast_system\n",
      "\tnoaa_goes16\n",
      "\tnoaa_goes17\n",
      "\tnoaa_gsod\n",
      "\tnoaa_historic_severe_storms\n",
      "\tnoaa_hurricanes\n",
      "\tnoaa_icoads\n",
      "\tnoaa_lightning\n",
      "\tnoaa_nwm\n",
      "\tnoaa_passive_acoustic_index\n",
      "\tnoaa_passive_bioacoustic\n",
      "\tnoaa_pifsc_metadata\n",
      "\tnoaa_preliminary_severe_storms\n",
      "\tnoaa_significant_earthquakes\n",
      "\tnoaa_tsunami\n",
      "\tnppes\n",
      "\tnrel_nsrdb\n",
      "\topen_buildings\n",
      "\topen_images\n",
      "\topen_targets_genetics\n",
      "\topen_targets_platform\n",
      "\topenaq\n",
      "\tpatents\n",
      "\tpatents_cpc\n",
      "\tpatents_dsep\n",
      "\tpatents_view\n",
      "\tpersistent_udfs\n",
      "\tproperati_properties_ar\n",
      "\tproperati_properties_br\n",
      "\tproperati_properties_cl\n",
      "\tproperati_properties_co\n",
      "\tproperati_properties_mx\n",
      "\tproperati_properties_pe\n",
      "\tproperati_properties_uy\n",
      "\tpypi\n",
      "\tsamples\n",
      "\tsan_francisco\n",
      "\tsan_francisco_311\n",
      "\tsan_francisco_bikeshare\n",
      "\tsan_francisco_film_locations\n",
      "\tsan_francisco_neighborhoods\n",
      "\tsan_francisco_sffd_service_calls\n",
      "\tsan_francisco_sfpd_incidents\n",
      "\tsan_francisco_transit_muni\n",
      "\tsan_francisco_trees\n",
      "\tsdoh_bea_cainc30\n",
      "\tsdoh_cdc_wonder_natality\n",
      "\tsdoh_cms_dual_eligible_enrollment\n",
      "\tsdoh_hrsa_shortage_areas\n",
      "\tsdoh_hud_housing\n",
      "\tsdoh_hud_pit_homelessness\n",
      "\tsdoh_snap_enrollment\n",
      "\tsec_quarterly_financials\n",
      "\tstackoverflow\n",
      "\tsunroof_solar\n",
      "\tthe_general_index\n",
      "\tthe_met\n",
      "\tthelook_ecommerce\n",
      "\tucb_fung_patent_data\n",
      "\tumiami_lincs\n",
      "\tun_sdg\n",
      "\tus_res_real_est_data\n",
      "\tusa_contagious_disease\n",
      "\tusa_names\n",
      "\tusda_nass_agriculture\n",
      "\tusfs_fia\n",
      "\tusitc_investigations\n",
      "\tuspto_oce_assignment\n",
      "\tuspto_oce_cancer\n",
      "\tuspto_oce_claims\n",
      "\tuspto_oce_litigation\n",
      "\tuspto_oce_office_actions\n",
      "\tuspto_oce_pair\n",
      "\tuspto_ptab\n",
      "\tutility_eu\n",
      "\tutility_us\n",
      "\twikipedia\n",
      "\twise_all_sky_data_release\n",
      "\tworld_bank_global_population\n",
      "\tworld_bank_health_population\n",
      "\tworld_bank_intl_debt\n",
      "\tworld_bank_intl_education\n",
      "\tworld_bank_wdi\n",
      "\tworldbank_wdi\n",
      "\tworldpop\n"
     ]
    }
   ],
   "source": [
    "# list datasets in the default project:\n",
    "flag = printDatasetList(client)  #: assigning to `flag` suppresses printing the return value (normally `True`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81uawTW5LFZo"
   },
   "source": [
    "This list should correspond to what is shown here https://bigquery.cloud.google.com/publicdatasets under the **bigquery-public-data** item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEAfjVxOLFZo"
   },
   "source": [
    "Here is how to create a dataset reference object by assigning a project and a dataset name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZrSaLIkWLFZo"
   },
   "outputs": [],
   "source": [
    "dataset_id = 'samples'\n",
    "dataset_ref = client.dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BlLbSA7LFZp"
   },
   "source": [
    "If our current project was something other than `bigquery-public-data`, we could still create this reference by specifying the project that contains the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NJK5yM9BLFZq"
   },
   "outputs": [],
   "source": [
    "dataset_id = 'samples'\n",
    "dataset_ref = client.dataset(dataset_id, project = 'bigquery-public-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_fYqMyGLFZr"
   },
   "source": [
    "How can we get the path of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "otqzZohpLFZs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/bigquery-public-data/datasets/samples'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#?\n",
    "dataset_ref.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRzK-hTuLFZt"
   },
   "source": [
    "Explore more of this object's members:\n",
    "\n",
    "*(HINT: Jupyter Notebooks does not support code completion, but Spyder and other Python IDEs do. If you copy all the above code to a Python file within the IDE, you can type `dataset_ref.` in a new line, then hit the [Tab] key to see the available members for the object.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "s9HM7PiMLFZt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _get_table_reference of DatasetReference('bigquery-public-data', 'samples')>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#?\n",
    "dataset_ref.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZB6yeerLFZu"
   },
   "source": [
    "Here is a function for listing the tables in a dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_E5S-MhtLFZu"
   },
   "outputs": [],
   "source": [
    "# function for listing tables in a dataset:\n",
    "def printTableList(client, dataset_id):\n",
    "    project = client.project\n",
    "    dataset_ref = client.dataset(dataset_id, project = project)    \n",
    "    tables = list(client.list_tables(dataset_ref))\n",
    "    if tables:\n",
    "        print('Tables in dataset {}:'.format(dataset_id))\n",
    "        for table in tables: \n",
    "            print('\\t{}'.format(table.table_id))\n",
    "        found = True\n",
    "    else:\n",
    "        print('{} dataset does not contain any tables.'.format(dataset_id))\n",
    "        found = False\n",
    "    return found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksp2VbNcLFZv"
   },
   "source": [
    "Use this function to list the tables in the current dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "F2KEisFzLFZv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in dataset samples:\n",
      "\tgithub_nested\n",
      "\tgithub_timeline\n",
      "\tgsod\n",
      "\tnatality\n",
      "\tshakespeare\n",
      "\ttrigrams\n",
      "\twikipedia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#?\n",
    "printTableList(client, 'samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoZPwFx1LFZx"
   },
   "source": [
    "To create a reference to a table within the dataset, we use the `table_id` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rYXUHik0LFZx"
   },
   "outputs": [],
   "source": [
    "table_id = 'shakespeare'\n",
    "table_ref = dataset_ref.table(table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MZOaAuiLFZy"
   },
   "source": [
    "Check the name of the table that `table_ref` now points to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6B9AAg4tLFZz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shakespeare\n"
     ]
    }
   ],
   "source": [
    "#?\n",
    "print(table_ref.table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOo7O5lVLFZ0"
   },
   "source": [
    "To access the data in the table itself, we use the `get_table()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rjnXTIoULFZ0"
   },
   "outputs": [],
   "source": [
    "table = client.get_table(table_ref)  # API Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ggy5pIrYLFZ2"
   },
   "source": [
    "NOTE: The contents of the table are not actually in our memory after this call! We are working with a Big Data platform, now, and we could easily end up pulling GBs or TBs of data by accident. \n",
    "\n",
    "To minimise data bandwidth, memory consumption, and processing time, Big Data platforms employ ***lazy evaluation***. This means that no computation or data transfer actually takes place until we *realise* (use) the data. Even if we execute subsequent code that performs calculations on the data, no data flow or computation actually occurs until we request output (e.g. by executing a print to stdout or writing to a file). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Sa9uV6tLFZ2"
   },
   "source": [
    "**What kind of object is returned by **`client.get_table`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "cdmNEp6ZLFZ3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Client.get_table of <google.cloud.bigquery.client.Client object at 0x000002A5964A41D0>>\n"
     ]
    }
   ],
   "source": [
    "#?\n",
    "print(client.get_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcaJMPCNLFZ4"
   },
   "source": [
    "How can we view the design of the table (column names and types? The name of the object attribute we need is the same term we learned in the module on databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "gt4FQZ88LFZ4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SchemaField('word', 'STRING', 'REQUIRED', None, 'A single unique word (where whitespace is the delimiter) extracted from a corpus.', (), None),\n",
       " SchemaField('word_count', 'INTEGER', 'REQUIRED', None, 'The number of times this word appears in this corpus.', (), None),\n",
       " SchemaField('corpus', 'STRING', 'REQUIRED', None, 'The work from which this word was extracted.', (), None),\n",
       " SchemaField('corpus_date', 'INTEGER', 'REQUIRED', None, 'The year in which this corpus was published.', (), None)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#?\n",
    "table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfaKrQRSLFZ6"
   },
   "source": [
    "Again, this is messy. If we wanted to refer to the column names and types in code, we might use something like this (which we could then parse into a dict):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8187Fu57LFZ6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word STRING', 'word_count INTEGER', 'corpus STRING', 'corpus_date INTEGER']\n"
     ]
    }
   ],
   "source": [
    "result = [\"{0} {1}\".format(schema.name,schema.field_type) for schema in table.schema]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQz7xhfwLFZ7"
   },
   "source": [
    "But if we just want to print them, here is another neat function for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_LqvAXo3LFZ7"
   },
   "outputs": [],
   "source": [
    "# function to print a table schema:\n",
    "def printTableSchema(aTable):\n",
    "    schemas = list(aTable.schema)\n",
    "    if schemas:\n",
    "        print('Table schema for {}:'.format(aTable.table_id))\n",
    "        for aSchema in schemas:\n",
    "            print('\\t{0} {1}'.format(aSchema.name, aSchema.field_type))\n",
    "        found = True\n",
    "    else:\n",
    "        found = False\n",
    "    return found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SROTDIm8LFZ8"
   },
   "source": [
    "Use this function to print the table schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table(TableReference(DatasetReference('bigquery-public-data', 'samples'), 'shakespeare'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "DpmWRmXmLFZ9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table schema for shakespeare:\n",
      "\tword STRING\n",
      "\tword_count INTEGER\n",
      "\tcorpus STRING\n",
      "\tcorpus_date INTEGER\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#?\n",
    "printTableSchema(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1YugUUhLFZ-"
   },
   "source": [
    "Now that we know what the columns are, we can write queries. Actually, we construct a query job by assigning an SQL statement to a method of the `client` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Gq7cGALfLFZ-"
   },
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 POST https://bigquery.googleapis.com/bigquery/v2/projects/bigquery-public-data/jobs?prettyPrint=false: Access Denied: Project bigquery-public-data: User does not have bigquery.jobs.create permission in project bigquery-public-data.\n\nLocation: None\nJob ID: ac066be0-203c-4345-84b3-0fe299459fac\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT COUNT(1) FROM `bigquery-public-data.samples.shakespeare`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m query_job\u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mquery(sql)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\cloud\\bigquery\\client.py:3403\u001b[0m, in \u001b[0;36mClient.query\u001b[1;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry, api_method)\u001b[0m\n\u001b[0;32m   3392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _job_helpers\u001b[38;5;241m.\u001b[39mquery_jobs_query(\n\u001b[0;32m   3393\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3394\u001b[0m         query,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3400\u001b[0m         job_retry,\n\u001b[0;32m   3401\u001b[0m     )\n\u001b[0;32m   3402\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m api_method \u001b[38;5;241m==\u001b[39m enums\u001b[38;5;241m.\u001b[39mQueryApiMethod\u001b[38;5;241m.\u001b[39mINSERT:\n\u001b[1;32m-> 3403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _job_helpers\u001b[38;5;241m.\u001b[39mquery_jobs_insert(\n\u001b[0;32m   3404\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3405\u001b[0m         query,\n\u001b[0;32m   3406\u001b[0m         job_config,\n\u001b[0;32m   3407\u001b[0m         job_id,\n\u001b[0;32m   3408\u001b[0m         job_id_prefix,\n\u001b[0;32m   3409\u001b[0m         location,\n\u001b[0;32m   3410\u001b[0m         project,\n\u001b[0;32m   3411\u001b[0m         retry,\n\u001b[0;32m   3412\u001b[0m         timeout,\n\u001b[0;32m   3413\u001b[0m         job_retry,\n\u001b[0;32m   3414\u001b[0m     )\n\u001b[0;32m   3415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected value for api_method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(api_method)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\cloud\\bigquery\\_job_helpers.py:114\u001b[0m, in \u001b[0;36mquery_jobs_insert\u001b[1;34m(client, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m query_job\n\u001b[1;32m--> 114\u001b[0m future \u001b[38;5;241m=\u001b[39m do_query()\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# The future might be in a failed state now, but if it's\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# unrecoverable, we'll find out when we ask for it's result, at which\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# point, we may retry.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m job_id_given:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\cloud\\bigquery\\_job_helpers.py:91\u001b[0m, in \u001b[0;36mquery_jobs_insert.<locals>.do_query\u001b[1;34m()\u001b[0m\n\u001b[0;32m     88\u001b[0m query_job \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mQueryJob(job_ref, query, client\u001b[38;5;241m=\u001b[39mclient, job_config\u001b[38;5;241m=\u001b[39mjob_config)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 91\u001b[0m     query_job\u001b[38;5;241m.\u001b[39m_begin(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core_exceptions\u001b[38;5;241m.\u001b[39mConflict \u001b[38;5;28;01mas\u001b[39;00m create_exc:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;66;03m# The thought is if someone is providing their own job IDs and they get\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# their job ID generation wrong, this could end up returning results for\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# the wrong query. We thus only try to recover if job ID was not given.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m job_id_given:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\cloud\\bigquery\\job\\query.py:1310\u001b[0m, in \u001b[0;36mQueryJob._begin\u001b[1;34m(self, client, retry, timeout)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;124;03m\"\"\"API call:  begin the job via a POST request\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \n\u001b[0;32m   1292\u001b[0m \u001b[38;5;124;03mSee\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;124;03m    ValueError: If the job has already begun.\u001b[39;00m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1310\u001b[0m     \u001b[38;5;28msuper\u001b[39m(QueryJob, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_begin(client\u001b[38;5;241m=\u001b[39mclient, retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mGoogleAPICallError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1312\u001b[0m     exc\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m=\u001b[39m _EXCEPTION_FOOTER_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1313\u001b[0m         message\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39mmessage, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation, job_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\n\u001b[0;32m   1314\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\cloud\\bigquery\\job\\base.py:693\u001b[0m, in \u001b[0;36m_AsyncJob._begin\u001b[1;34m(self, client, retry, timeout)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;66;03m# jobs.insert is idempotent because we ensure that every new\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;66;03m# job has an ID.\u001b[39;00m\n\u001b[0;32m    692\u001b[0m span_attributes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path}\n\u001b[1;32m--> 693\u001b[0m api_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39m_call_api(\n\u001b[0;32m    694\u001b[0m     retry,\n\u001b[0;32m    695\u001b[0m     span_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBigQuery.job.begin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    696\u001b[0m     span_attributes\u001b[38;5;241m=\u001b[39mspan_attributes,\n\u001b[0;32m    697\u001b[0m     job_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    698\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    699\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m    700\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_api_repr(),\n\u001b[0;32m    701\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    702\u001b[0m )\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_properties(api_response)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\cloud\\bigquery\\client.py:813\u001b[0m, in \u001b[0;36mClient._call_api\u001b[1;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[0;32m    811\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[0;32m    812\u001b[0m     ):\n\u001b[1;32m--> 813\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m call()\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\api_core\\retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    346\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    348\u001b[0m )\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    350\u001b[0m     target,\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    352\u001b[0m     sleep_generator,\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    354\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    355\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\api_core\\retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m target()\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\cloud\\_http\\__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[1;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[0;32m    482\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    483\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    484\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m     extra_api_info\u001b[38;5;241m=\u001b[39mextra_api_info,\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[1;31mForbidden\u001b[0m: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/bigquery-public-data/jobs?prettyPrint=false: Access Denied: Project bigquery-public-data: User does not have bigquery.jobs.create permission in project bigquery-public-data.\n\nLocation: None\nJob ID: ac066be0-203c-4345-84b3-0fe299459fac\n"
     ]
    }
   ],
   "source": [
    "sql = \"SELECT COUNT(1) FROM `bigquery-public-data.samples.shakespeare`\"\n",
    "query_job= client.query(sql)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJVssU3mLFZ_"
   },
   "source": [
    "Why does this throw an error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4feq3JaqLFZ_"
   },
   "source": [
    "ANSWER: \n",
    "Access denied because user doesn't have the connectin of the data for which the argument has been passed.\n",
    "_____________________________________________________\n",
    "\n",
    "So, what can we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "hCVH3AxrLFaA"
   },
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 POST https://bigquery.googleapis.com/bigquery/v2/projects/spry-acolyte-384422/jobs?prettyPrint=false: Access Denied: Project spry-acolyte-384422: User does not have bigquery.jobs.create permission in project spry-acolyte-384422.\n\nLocation: None\nJob ID: 14373dad-b036-4ba7-89fc-e4cfcee73097\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT COUNT(1) FROM `bigquery-public-data.samples.shakespeare`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m con \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mClient\u001b[38;5;241m.\u001b[39mfrom_service_account_json(key_path,project \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspry-acolyte-384422\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m a\u001b[38;5;241m=\u001b[39mcon\u001b[38;5;241m.\u001b[39mquery(sql)\n\u001b[0;32m      5\u001b[0m a\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\cloud\\bigquery\\client.py:3403\u001b[0m, in \u001b[0;36mClient.query\u001b[1;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry, api_method)\u001b[0m\n\u001b[0;32m   3392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _job_helpers\u001b[38;5;241m.\u001b[39mquery_jobs_query(\n\u001b[0;32m   3393\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3394\u001b[0m         query,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3400\u001b[0m         job_retry,\n\u001b[0;32m   3401\u001b[0m     )\n\u001b[0;32m   3402\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m api_method \u001b[38;5;241m==\u001b[39m enums\u001b[38;5;241m.\u001b[39mQueryApiMethod\u001b[38;5;241m.\u001b[39mINSERT:\n\u001b[1;32m-> 3403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _job_helpers\u001b[38;5;241m.\u001b[39mquery_jobs_insert(\n\u001b[0;32m   3404\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3405\u001b[0m         query,\n\u001b[0;32m   3406\u001b[0m         job_config,\n\u001b[0;32m   3407\u001b[0m         job_id,\n\u001b[0;32m   3408\u001b[0m         job_id_prefix,\n\u001b[0;32m   3409\u001b[0m         location,\n\u001b[0;32m   3410\u001b[0m         project,\n\u001b[0;32m   3411\u001b[0m         retry,\n\u001b[0;32m   3412\u001b[0m         timeout,\n\u001b[0;32m   3413\u001b[0m         job_retry,\n\u001b[0;32m   3414\u001b[0m     )\n\u001b[0;32m   3415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected value for api_method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(api_method)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\cloud\\bigquery\\_job_helpers.py:114\u001b[0m, in \u001b[0;36mquery_jobs_insert\u001b[1;34m(client, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m query_job\n\u001b[1;32m--> 114\u001b[0m future \u001b[38;5;241m=\u001b[39m do_query()\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# The future might be in a failed state now, but if it's\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# unrecoverable, we'll find out when we ask for it's result, at which\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# point, we may retry.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m job_id_given:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\cloud\\bigquery\\_job_helpers.py:91\u001b[0m, in \u001b[0;36mquery_jobs_insert.<locals>.do_query\u001b[1;34m()\u001b[0m\n\u001b[0;32m     88\u001b[0m query_job \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mQueryJob(job_ref, query, client\u001b[38;5;241m=\u001b[39mclient, job_config\u001b[38;5;241m=\u001b[39mjob_config)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 91\u001b[0m     query_job\u001b[38;5;241m.\u001b[39m_begin(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core_exceptions\u001b[38;5;241m.\u001b[39mConflict \u001b[38;5;28;01mas\u001b[39;00m create_exc:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;66;03m# The thought is if someone is providing their own job IDs and they get\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# their job ID generation wrong, this could end up returning results for\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# the wrong query. We thus only try to recover if job ID was not given.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m job_id_given:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\cloud\\bigquery\\job\\query.py:1310\u001b[0m, in \u001b[0;36mQueryJob._begin\u001b[1;34m(self, client, retry, timeout)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;124;03m\"\"\"API call:  begin the job via a POST request\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \n\u001b[0;32m   1292\u001b[0m \u001b[38;5;124;03mSee\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;124;03m    ValueError: If the job has already begun.\u001b[39;00m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1310\u001b[0m     \u001b[38;5;28msuper\u001b[39m(QueryJob, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_begin(client\u001b[38;5;241m=\u001b[39mclient, retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mGoogleAPICallError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1312\u001b[0m     exc\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m=\u001b[39m _EXCEPTION_FOOTER_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1313\u001b[0m         message\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39mmessage, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation, job_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\n\u001b[0;32m   1314\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\cloud\\bigquery\\job\\base.py:693\u001b[0m, in \u001b[0;36m_AsyncJob._begin\u001b[1;34m(self, client, retry, timeout)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;66;03m# jobs.insert is idempotent because we ensure that every new\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;66;03m# job has an ID.\u001b[39;00m\n\u001b[0;32m    692\u001b[0m span_attributes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path}\n\u001b[1;32m--> 693\u001b[0m api_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39m_call_api(\n\u001b[0;32m    694\u001b[0m     retry,\n\u001b[0;32m    695\u001b[0m     span_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBigQuery.job.begin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    696\u001b[0m     span_attributes\u001b[38;5;241m=\u001b[39mspan_attributes,\n\u001b[0;32m    697\u001b[0m     job_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    698\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    699\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m    700\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_api_repr(),\n\u001b[0;32m    701\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    702\u001b[0m )\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_properties(api_response)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\cloud\\bigquery\\client.py:813\u001b[0m, in \u001b[0;36mClient._call_api\u001b[1;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[0;32m    811\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[0;32m    812\u001b[0m     ):\n\u001b[1;32m--> 813\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m call()\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\api_core\\retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    346\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    348\u001b[0m )\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    350\u001b[0m     target,\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    352\u001b[0m     sleep_generator,\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    354\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    355\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\api_core\\retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m target()\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\class2\\Lib\\site-packages\\google\\cloud\\_http\\__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[1;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[0;32m    482\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    483\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    484\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m     extra_api_info\u001b[38;5;241m=\u001b[39mextra_api_info,\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[1;31mForbidden\u001b[0m: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/spry-acolyte-384422/jobs?prettyPrint=false: Access Denied: Project spry-acolyte-384422: User does not have bigquery.jobs.create permission in project spry-acolyte-384422.\n\nLocation: None\nJob ID: 14373dad-b036-4ba7-89fc-e4cfcee73097\n"
     ]
    }
   ],
   "source": [
    "#?\n",
    "sql = \"SELECT COUNT(1) FROM `bigquery-public-data.samples.shakespeare`\"\n",
    "con = bigquery.Client.from_service_account_json(key_path,project ='spry-acolyte-384422')\n",
    "a=con.query(sql)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTfuF8J0LFaA"
   },
   "source": [
    "If that worked, show what query_job is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmiGhS0ALFaA"
   },
   "outputs": [],
   "source": [
    "#?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Src6_5auLFaB"
   },
   "source": [
    "Once again, due to lazy execution, no actual execution occurs until we request output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCz4Yw9jLFaB"
   },
   "outputs": [],
   "source": [
    "for row in query_job:  # API request - fetches results\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQG3a1oALFaC"
   },
   "source": [
    "And, again, we need to manipulate this to make it neat. Each member of the rowset is a list and we only want to extract the value, which is in the first member:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qcq2F5vzLFaC"
   },
   "outputs": [],
   "source": [
    "print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPqWb1_YLFaD"
   },
   "source": [
    "So, we now know that this table has 164,656 rows. (We would not want to print it!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6idZY0-3LFaD"
   },
   "source": [
    "A better coding practice is to write SQL statements that assign names (aliases) to derived values, so we don't forget what the resulting rowset contains. Rewrite the above SQL statement so that the value returned is aliased a \"num_rows\", and assign the QueryJob as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NeHVJAm5LFaD"
   },
   "outputs": [],
   "source": [
    "#?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUFlZ66lLFaE"
   },
   "source": [
    "Now we could use Python's `assert` statement to build a test into the first code block that operates on the rowset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6MHaNZh0LFaE"
   },
   "outputs": [],
   "source": [
    "for row in query_job:  # API request - fetches results\n",
    "    # Row values can be accessed by field name or index:\n",
    "    assert row[0] == row.num_rows == row['num_rows']  #: for debugging bad sql\n",
    "    print(row.num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fP4GpU02LFaF"
   },
   "source": [
    "The above code checks that the name attribute of the value in `row[0]` is what we expected (i.e. \"num_rows\"). Also, it shows that we can refer to a field in a row by its object member `num_rows` or by using the same notation we use for Python dictionaries, `['num_rows']`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y83gunLZLFaF"
   },
   "source": [
    "Write, execute, and print the results of a query that fetches 10 rows from the table, each containing the \"word\", \"word_count\", and \"corpus\" fields: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhvBwHzpLFaG"
   },
   "outputs": [],
   "source": [
    "#?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlGpm9dmLFaH"
   },
   "source": [
    "(NOTE: Using `assert` religiously is good practice and will make debugging easier, but is probably overkill for non-production code.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "md6tWVvHLFaH"
   },
   "source": [
    "Whenever you catch yourself writing a swag of code to do something that seems rudimentary or low-level, there is a very good chance that you don't need to. A much easier way to handle the above requirement is to use the `to_dataframe` method of the QueryJob object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19bjagBHLFaH"
   },
   "outputs": [],
   "source": [
    "df = query_job.to_dataframe()\n",
    "print(df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qc7vdIfALFaJ"
   },
   "source": [
    "Although the above doesn't use `assert` (which you might still want to include in some test code), you will be able to tell at a glance if something is wrong with the contents of the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsWSuO95LFaJ"
   },
   "source": [
    "#### Final Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mKynMuNLFaJ"
   },
   "source": [
    "1. Here is a readable way to code long SQL statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nm7i1-rLFaJ"
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT word, word_count, corpus \n",
    "    FROM `bigquery-public-data.samples.shakespeare` \n",
    "    LIMIT 10\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1j2w1aovLFaK"
   },
   "source": [
    "2. If you had an application that needed to modify the tables or datasets in the `bigquery-public-data` is project, you could copy them to our own project, where you would have the permissions to do as you please with the data (subject to Google's terms of use)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOAZyGTcLFaL"
   },
   "source": [
    "3. We aren't limited to the datasets that are already in BigQuery. We can upload tables from our computer, and we can pull data in from other online sources. We will cover these tasks in another module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJmK2n7vLFaL"
   },
   "source": [
    "#### Next Steps\n",
    "\n",
    "If you wish to pick up a few more skills you can go to https://cloud.google.com/bigquery/create-simple-app-api. (Note that we have already been through the preliminaries, so you can start at \"Download the sample code\".)\n",
    "\n",
    "Alternatively, you can take a deeper dive into the API here: https://googlecloudplatform.github.io/google-cloud-python/latest/bigquery/usage.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFNsekmxLFaM"
   },
   "source": [
    "## - END -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBAJLLeXLHs8"
   },
   "source": [
    ">\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1AVU7q-LIuO"
   },
   "source": [
    ">\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fpehj_5ELJk9"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > >  2023 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "PJmK2n7vLFaL"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
